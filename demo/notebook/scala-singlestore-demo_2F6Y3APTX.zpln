{
 "paragraphs": [
  {
   "text": "%md\n## This is a small demo that illustrates the usage of the SingleStore-Spark connector. \n#### It connects to the ciab docker container (https://hub.docker.com/r/memsql/cluster-in-a-box) and runs some basic queries on it.",
   "user": "anonymous",
   "dateUpdated": "2021-02-17 10:37:13.779",
   "progress": 0,
   "config": {
    "editorSetting": {
     "language": "markdown",
     "editOnDblClick": true,
     "completionKey": "TAB",
     "completionSupport": false
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/markdown",
    "fontSize": 15.0,
    "results": {},
    "enabled": true,
    "editorHide": true,
    "tableHide": false
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "HTML",
      "data": "<div class=\"markdown-body\">\n<h2>This is a small demo that illustrates the usage of the SingleStore-Spark connector.</h2>\n<h4>It connects to the ciab docker container (<a href=\"https://hub.docker.com/r/memsql/cluster-in-a-box\">https://hub.docker.com/r/memsql/cluster-in-a-box</a>) and runs some basic queries on it.</h4>\n\n</div>"
     }
    ]
   },
   "apps": [],
   "runtimeInfos": {},
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1587553015155_-1751456317",
   "id": "paragraph_1587550420891_1388924274",
   "dateCreated": "2020-04-22 10:56:55.155",
   "dateStarted": "2021-02-17 10:37:13.785",
   "dateFinished": "2021-02-17 10:37:13.795",
   "status": "FINISHED"
  },
  {
   "title": "Configure Spark",
   "text": "%spark.conf\n\n// Comma-separated list of Maven coordinates of jars to include on the driver and executor classpaths\nspark.jars.packages com.singlestore:singlestore-spark-connector_2.11:3.0.8-spark-2.4.4\n\n// Hostname or IP address of the SingleStore Master Aggregator in the format host[:port] (port is optional). \n// singlestore-ciab-for-zeppelin - hostname of the docker created by https://hub.docker.com/r/memsql/cluster-in-a-box\n// 3306 - port on which SingleStore Master Aggregator is started\nspark.datasource.singlestore.ddlEndpoint singlestore-ciab-for-zeppelin:3306\n\n// Hostname or IP address of SingleStore Aggregator nodes to run queries against in the format host[:port],host[:port],...\n// (port is optional, multiple hosts separated by comma) (default: ddlEndpoint)\n// Example\n// spark.datasource.singlestore.dmlEndpoints child-agg:3308,child-agg2\nspark.datasource.singlestore.dmlEndpoints singlestore-ciab-for-zeppelin:3306\n\n// SingleStore username (default: root)\nspark.datasource.singlestore.user root\n\n// SingleStore password (default: no password)\nspark.datasource.singlestore.password password\n\n// If set, all connections will default to using this database (default: empty)\n// Example\n// spark.datasource.singlestore.database demoDB\nspark.datasource.singlestore.database\n\n// Disable SQL Pushdown when running queries (default: false)\nspark.datasource.singlestore.disablePushdown false\n\n// Enable reading data in parallel for some query shapes (default: false)\nspark.datasource.singlestore.enableParallelRead false\n\n// Truncate instead of drop an existing table during Overwrite (default: false)\nspark.datasource.singlestore.truncate false\n\n// Compress data on load; one of (GZip, LZ4, Skip) (default: GZip)\nspark.datasource.singlestore.loadDataCompression GZip\n\n// Specify additional keys to add to tables created by the connector\n// Examples\n// * A primary key on the id column\n// spark.datasource.singlestore.tableKey.primary id\n// * A regular key on the columns created, firstname with the key name created_firstname\n// spark.datasource.singlestore.tableKey.key.created_firstname created, firstName\n// * A unique key on the username column\n// spark.datasource.singlestore.tableKey.unique username\nspark.datasource.singlestore.tableKey",
   "user": "anonymous",
   "dateUpdated": "2021-02-17 10:37:13.883",
   "progress": 0,
   "config": {
    "lineNumbers": false,
    "tableHide": false,
    "editorSetting": {
     "language": "text",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 12.0,
    "editorMode": "ace/mode/text",
    "fontSize": 13.0,
    "title": true,
    "results": {},
    "enabled": true,
    "editorHide": false
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": []
   },
   "apps": [],
   "runtimeInfos": {},
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1587553015155_499760817",
   "id": "paragraph_1587546884632_-2089202077",
   "dateCreated": "2020-04-22 10:56:55.155",
   "dateStarted": "2021-02-17 10:37:13.887",
   "dateFinished": "2021-02-17 10:37:13.890",
   "status": "FINISHED"
  },
  {
   "title": "Create a database using JDBC",
   "text": "import java.sql.{Connection, DriverManager}\nimport java.util.{Properties, TimeZone}\n\nval connProperties = new Properties()\nconnProperties.put(\"user\", \"root\")\nconnProperties.put(\"password\", \"password\")\n\nval conn = DriverManager.getConnection(\n        s\"jdbc:mysql://singlestore-ciab-for-zeppelin\",\n        connProperties\n      )\n\nval statement = conn.createStatement()\nstatement.execute(\"create database if not exists demoDB\")\nstatement.close()\nconn.close()",
   "user": "anonymous",
   "dateUpdated": "2021-02-17 10:37:13.985",
   "progress": 0,
   "config": {
    "colWidth": 12.0,
    "fontSize": 13.0,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala",
    "title": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "import java.sql.{Connection, DriverManager}\nimport java.util.{Properties, TimeZone}\n\u001b[1m\u001b[34mconnProperties\u001b[0m: \u001b[1m\u001b[32mjava.util.Properties\u001b[0m = {user=root, password=password}\n\u001b[1m\u001b[34mconn\u001b[0m: \u001b[1m\u001b[32mjava.sql.Connection\u001b[0m = org.mariadb.jdbc.MariaDbConnection@1b977ae4\n\u001b[1m\u001b[34mstatement\u001b[0m: \u001b[1m\u001b[32mjava.sql.Statement\u001b[0m = org.mariadb.jdbc.MariaDbStatement@494e9f9d\n"
     }
    ]
   },
   "apps": [],
   "runtimeInfos": {},
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1587581984336_-994182625",
   "id": "paragraph_1587581984336_-994182625",
   "dateCreated": "2020-04-22 18:59:44.336",
   "dateStarted": "2021-02-17 10:37:13.987",
   "dateFinished": "2021-02-17 10:37:29.652",
   "status": "FINISHED"
  },
  {
   "title": "Writing to SingleStore",
   "text": "import org.apache.spark.sql.{SaveMode}\n\nval people1 = spark.createDataFrame(Seq(\n    (1, \"andy\", 5, \"USA\"), \n    (2, \"jeff\", 23, \"China\"), \n    (3, \"james\", 62, \"USA\")\n    )).toDF(\"id\", \"name\", \"age\", \"country\")\npeople1.show()\n\npeople1.write\n    .format(\"singlestore\")\n    .mode(SaveMode.Overwrite) // recreate table if it exists\n    .save(\"demoDB.people\") // write to table `people` in database `demoDB`\n    \nval people2 = people1.withColumn(\"age2\", $\"age\" + 1)\npeople2.show()\n\npeople2.write\n    .format(\"singlestore\")\n    .option(\"loadDataCompression\", \"LZ4\") // compress data on load with LZ4\n    .mode(SaveMode.Overwrite) // recreate table if it exists\n    .save(\"demoDB.people\") // write to table `people` in database `demoDB` ",
   "user": "anonymous",
   "dateUpdated": "2021-02-17 10:37:29.701",
   "progress": 100,
   "config": {
    "lineNumbers": true,
    "tableHide": false,
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 6.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 13.0,
    "editorHide": false,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "+---+-----+---+-------+\n| id| name|age|country|\n+---+-----+---+-------+\n|  1| andy|  5|    USA|\n|  2| jeff| 23|  China|\n|  3|james| 62|    USA|\n+---+-----+---+-------+\n\n+---+-----+---+-------+----+\n| id| name|age|country|age2|\n+---+-----+---+-------+----+\n|  1| andy|  5|    USA|   6|\n|  2| jeff| 23|  China|  24|\n|  3|james| 62|    USA|  63|\n+---+-----+---+-------+----+\n\nimport org.apache.spark.sql.SaveMode\n\u001b[1m\u001b[34mpeople1\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [id: int, name: string ... 2 more fields]\n\u001b[1m\u001b[34mpeople2\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [id: int, name: string ... 3 more fields]\n"
     }
    ]
   },
   "apps": [],
   "runtimeInfos": {
    "jobUrl": {
     "propertyName": "jobUrl",
     "label": "SPARK JOB",
     "tooltip": "View in Spark web UI",
     "group": "spark",
     "values": [
      {
       "jobUrl": "http://199765aa5b67:4040/jobs/job?id=0"
      },
      {
       "jobUrl": "http://199765aa5b67:4040/jobs/job?id=1"
      }
     ],
     "interpreterSettingId": "spark"
    }
   },
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1587553015156_498470796",
   "id": "paragraph_1587547555609_-348809680",
   "dateCreated": "2020-04-22 10:56:55.156",
   "dateStarted": "2021-02-17 10:37:29.703",
   "dateFinished": "2021-02-17 10:37:34.247",
   "status": "FINISHED"
  },
  {
   "title": "Reading from SingleStore",
   "text": "val people = spark.read\n    .format(\"singlestore\")\n    .load(\"demoDB.people\")\npeople.show()\n\nval children = spark.read\n    .format(\"singlestore\")\n    .load(\"demoDB.people\")\n    .filter($\"age\" < 10)\nchildren.show()",
   "user": "anonymous",
   "dateUpdated": "2021-02-17 10:37:34.306",
   "progress": 100,
   "config": {
    "tableHide": false,
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "colWidth": 6.0,
    "editorMode": "ace/mode/scala",
    "fontSize": 13.0,
    "title": true,
    "results": {},
    "enabled": true
   },
   "settings": {
    "params": {},
    "forms": {}
   },
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "+---+-----+---+-------+----+\n| id| name|age|country|age2|\n+---+-----+---+-------+----+\n|  3|james| 62|    USA|  63|\n|  2| jeff| 23|  China|  24|\n|  1| andy|  5|    USA|   6|\n+---+-----+---+-------+----+\n\n+---+----+---+-------+----+\n| id|name|age|country|age2|\n+---+----+---+-------+----+\n|  1|andy|  5|    USA|   6|\n+---+----+---+-------+----+\n\n\u001b[1m\u001b[34mpeople\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [id: int, name: string ... 3 more fields]\n\u001b[1m\u001b[34mchildren\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [id: int, name: string ... 3 more fields]\n"
     }
    ]
   },
   "apps": [],
   "runtimeInfos": {
    "jobUrl": {
     "propertyName": "jobUrl",
     "label": "SPARK JOB",
     "tooltip": "View in Spark web UI",
     "group": "spark",
     "values": [
      {
       "jobUrl": "http://199765aa5b67:4040/jobs/job?id=2"
      },
      {
       "jobUrl": "http://199765aa5b67:4040/jobs/job?id=3"
      }
     ],
     "interpreterSettingId": "spark"
    }
   },
   "progressUpdateIntervalMs": 500,
   "jobName": "paragraph_1587553015156_-836094162",
   "id": "paragraph_1587548897148_-478225566",
   "dateCreated": "2020-04-22 10:56:55.156",
   "dateStarted": "2021-02-17 10:37:34.309",
   "dateFinished": "2021-02-17 10:37:35.533",
   "status": "FINISHED"
  }
 ],
 "name": "scala-singlestore-demo",
 "id": "2F6Y3APTX",
 "defaultInterpreterGroup": "spark",
 "version": "0.9.0-preview1",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false
 },
 "info": {
  "isRunning": true
 }
}