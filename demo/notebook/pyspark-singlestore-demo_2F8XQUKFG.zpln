{
  "paragraphs": [
    {
      "text": "%md\n## This is a small demo that illustrates the usage of the SingleStore-Spark connector. \n#### It connects to the ciab docker container (https://hub.docker.com/r/memsql/cluster-in-a-box) and runs some basic queries on it.",
      "user": "anonymous",
      "dateUpdated": "2021-02-17 10:52:15.420",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 15.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eThis is a small demo that illustrates the usage of the SingleStore-Spark connector.\u003c/h2\u003e\n\u003ch4\u003eIt connects to the ciab docker container (\u003ca href\u003d\"https://hub.docker.com/r/memsql/cluster-in-a-box\"\u003ehttps://hub.docker.com/r/memsql/cluster-in-a-box\u003c/a\u003e) and runs some basic queries on it.\u003c/h4\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1587553845758_1676143899",
      "id": "paragraph_1587550420891_1388924274",
      "dateCreated": "2020-04-22 11:10:45.758",
      "dateStarted": "2021-02-17 10:52:15.434",
      "dateFinished": "2021-02-17 10:52:17.260",
      "status": "FINISHED"
    },
    {
      "title": "Configure Spark",
      "text": "%spark.conf\n\n// Comma-separated list of Maven coordinates of jars to include on the driver and executor classpaths\nspark.jars.packages com.singlestore:singlestore-spark-connector_2.12:3.1.1-spark-3.0.0\n\n// Hostname or IP address of the SingleStore Master Aggregator in the format host[:port] (port is optional). \n// singlestore-ciab-for-zeppelin - hostname of the docker created by https://hub.docker.com/r/memsql/cluster-in-a-box\n// 3306 - port on which SingleStore Master Aggregator is started\nspark.datasource.singlestore.ddlEndpoint singlestore-ciab-for-zeppelin:3306\n\n// Hostname or IP address of SingleStore Aggregator nodes to run queries against in the format host[:port],host[:port],...\n// (port is optional, multiple hosts separated by comma) (default: ddlEndpoint)\n// Example\n// spark.datasource.singlestore.dmlEndpoints child-agg:3308,child-agg2\nspark.datasource.singlestore.dmlEndpoints singlestore-ciab-for-zeppelin:3306\n\n// SingleStore username (default: root)\nspark.datasource.singlestore.user root\n\n// SingleStore password (default: no password)\nspark.datasource.singlestore.password password\n\n// If set, all connections will default to using this database (default: empty)\n// Example\n// spark.datasource.singlestore.database demoDB\nspark.datasource.singlestore.database\n\n// Disable SQL Pushdown when running queries (default: false)\nspark.datasource.singlestore.disablePushdown false\n\n// Enable reading data in parallel for some query shapes (default: false)\nspark.datasource.singlestore.enableParallelRead false\n\n// Truncate instead of drop an existing table during Overwrite (default: false)\nspark.datasource.singlestore.truncate false\n\n// Compress data on load; one of (GZip, LZ4, Skip) (default: GZip)\nspark.datasource.singlestore.loadDataCompression GZip\n\n// Specify additional keys to add to tables created by the connector\n// Examples\n// * A primary key on the id column\n// spark.datasource.singlestore.tableKey.primary id\n// * A regular key on the columns created, firstname with the key name created_firstname\n// spark.datasource.singlestore.tableKey.key.created_firstname created, firstName\n// * A unique key on the username column\n// spark.datasource.singlestore.tableKey.unique username\nspark.datasource.singlestore.tableKey",
      "user": "anonymous",
      "dateUpdated": "2021-02-17 10:52:17.333",
      "progress": 0,
      "config": {
        "lineNumbers": false,
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "fontSize": 13.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1587553845761_760134801",
      "id": "paragraph_1587546884632_-2089202077",
      "dateCreated": "2020-04-22 11:10:45.761",
      "dateStarted": "2021-02-17 10:52:17.340",
      "dateFinished": "2021-02-17 10:52:17.363",
      "status": "FINISHED"
    },
    {
      "title": "Create a database using JDBC",
      "text": "import java.sql.{Connection, DriverManager}\nimport java.util.{Properties, TimeZone}\n\nval connProperties \u003d new Properties()\nconnProperties.put(\"user\", \"root\")\nconnProperties.put(\"password\", \"password\")\n\nval conn \u003d DriverManager.getConnection(\n        s\"jdbc:mysql://singlestore-ciab-for-zeppelin\",\n        connProperties\n      )\n\nval statement \u003d conn.createStatement()\nstatement.execute(\"create database if not exists demoDB\")\nstatement.close()\nconn.close()",
      "user": "anonymous",
      "dateUpdated": "2021-02-17 10:52:17.437",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 13.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import java.sql.{Connection, DriverManager}\nimport java.util.{Properties, TimeZone}\n\u001b[1m\u001b[34mconnProperties\u001b[0m: \u001b[1m\u001b[32mjava.util.Properties\u001b[0m \u003d {user\u003droot, password\u003dpassword}\n\u001b[1m\u001b[34mconn\u001b[0m: \u001b[1m\u001b[32mjava.sql.Connection\u001b[0m \u003d org.mariadb.jdbc.MariaDbConnection@300ce398\n\u001b[1m\u001b[34mstatement\u001b[0m: \u001b[1m\u001b[32mjava.sql.Statement\u001b[0m \u003d org.mariadb.jdbc.MariaDbStatement@535eba7a\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1587585329076_1567672881",
      "id": "paragraph_1587585329076_1567672881",
      "dateCreated": "2020-04-22 19:55:29.076",
      "dateStarted": "2021-02-17 10:52:17.441",
      "dateFinished": "2021-02-17 10:53:06.307",
      "status": "FINISHED"
    },
    {
      "title": "Writing to SingleStore",
      "text": "%spark.pyspark\n\npeople1 \u003d spark.createDataFrame([\n    (1, \"andy\", 5, \"USA\"), \n    (2, \"jeff\", 23, \"China\"), \n    (3, \"james\", 62, \"USA\")\n    ]).toDF(\"id\", \"name\", \"age\", \"country\")\npeople1.printSchema\npeople1.show()\n\npeople1.write \\\n    .format(\"singlestore\") \\\n    .mode(\"overwrite\") \\\n    .save(\"demoDB.people\") # write to table `people` in database `demoDB`\n    \npeople2 \u003d people1.withColumn(\"age2\", people1[\"age\"] + 1)\npeople1.printSchema\npeople2.show()\n\npeople2.write \\\n    .format(\"singlestore\") \\\n    .option(\"loadDataCompression\", \"LZ4\") \\\n    .mode(\"overwrite\") \\\n    .save(\"demoDB.people\") # write to table `people` in database `demoDB` ",
      "user": "anonymous",
      "dateUpdated": "2021-02-17 10:53:06.399",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 13.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+---+-------+\n| id| name|age|country|\n+---+-----+---+-------+\n|  1| andy|  5|    USA|\n|  2| jeff| 23|  China|\n|  3|james| 62|    USA|\n+---+-----+---+-------+\n\n+---+-----+---+-------+----+\n| id| name|age|country|age2|\n+---+-----+---+-------+----+\n|  1| andy|  5|    USA|   6|\n|  2| jeff| 23|  China|  24|\n|  3|james| 62|    USA|  63|\n+---+-----+---+-------+----+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d1"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d2"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d4"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d5"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d6"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d7"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1587553845761_-1027258033",
      "id": "paragraph_1587547555609_-348809680",
      "dateCreated": "2020-04-22 11:10:45.761",
      "dateStarted": "2021-02-17 10:53:06.406",
      "dateFinished": "2021-02-17 10:53:18.888",
      "status": "FINISHED"
    },
    {
      "title": "Reading from SingleStore",
      "text": "%spark.pyspark\n\npeople \u003d spark.read \\\n    .format(\"singlestore\") \\\n    .load(\"demoDB.people\")\npeople.printSchema\npeople.show()\n\nchildren \u003d spark.read \\\n    .format(\"singlestore\") \\\n    .load(\"demoDB.people\") \\\n    .filter(\"age \u003c 10\")\npeople.printSchema\nchildren.show()",
      "user": "anonymous",
      "dateUpdated": "2021-02-17 10:53:18.939",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/python",
        "fontSize": 13.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+---+-------+----+\n| id| name|age|country|age2|\n+---+-----+---+-------+----+\n|  2| jeff| 23|  China|  24|\n|  1| andy|  5|    USA|   6|\n|  3|james| 62|    USA|  63|\n+---+-----+---+-------+----+\n\n+---+----+---+-------+----+\n| id|name|age|country|age2|\n+---+----+---+-------+----+\n|  1|andy|  5|    USA|   6|\n+---+----+---+-------+----+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://834f7cebbd9d:4040/jobs/job?id\u003d9"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1587553845762_-1342936354",
      "id": "paragraph_1587548897148_-478225566",
      "dateCreated": "2020-04-22 11:10:45.762",
      "dateStarted": "2021-02-17 10:53:18.969",
      "dateFinished": "2021-02-17 10:53:21.162",
      "status": "FINISHED"
    }
  ],
  "name": "pyspark-singlestore-demo",
  "id": "2F8XQUKFG",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {
    "isRunning": true
  }
}